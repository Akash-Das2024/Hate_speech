{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aIpGb1wLMFBl",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679242457682,
          "user_tz": -330,
          "elapsed": 8505,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396d42ac-81f0-4658-dfed-a208f372698d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# preprocessing the data\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    # Tokenize the sentence\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    \n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Stem each word\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    # Lemmatize each word\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
        "    \n",
        "    # Join the tokens back into a sentence\n",
        "    cleaned_sentence = ' '.join(lemmatized_tokens)\n",
        "    \n",
        "    return cleaned_sentence\n",
        "\n",
        "\n",
        "def detect_offensive(statement):\n",
        "    \"\"\"\n",
        "    This function takes in a statement as input and returns True if it is offensive, and False otherwise.\n",
        "    \"\"\"\n",
        "    blob = TextBlob(statement)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity < -0.5:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Load the data into a pandas dataframe\n",
        "# df = pd.read_csv(\"data.csv\")\n",
        "# print(df['text'].head(5))\n",
        "# df['text'] = df['text'].apply(preprocess_sentence)\n",
        "# print(df['text'].head(5))\n",
        "\n",
        "df2 = pd.read_csv(\"data2.csv\")\n",
        "df2['tweet'] = df2['tweet'].apply(preprocess_sentence)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df['text'], df['task1'], test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2['tweet'], df2['class'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the text data into numerical features using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier on the training data\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the performance of the classifier on the testing data\n",
        "accuracy = nb.score(X_test, y_test)\n",
        "precision = nb.score(X_test, y_test == 1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdQxFMfdzuYV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679242511648,
          "user_tz": -330,
          "elapsed": 517,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "d392f2a5-b89f-4688-82c2-49705ab58622"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8323185011709602\n",
            "Precision: 0.7386416861826698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the method Used:  score = Summation of (1 + log(tf))\n",
        "\n",
        "def basemodel(rs):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df2['tweet'], df2['class'], test_size=0.2, random_state=rs)\n",
        "    # evaluting the vocabulary\n",
        "    vocab = set()\n",
        "    for sentence in X_train:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "\n",
        "    # Create a dictionary to store the count of each word in each class\n",
        "    # array of index = word for all labels\n",
        "    # count how many time a word occured in each labels\n",
        "\n",
        "    class_word_counts = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_counts[c] = {}\n",
        "        for word in vocab:\n",
        "            class_word_counts[c][word] = 0\n",
        "\n",
        "    # Count the number of occurrences of each word in each class\n",
        "    for i in range(len(X_train)):\n",
        "        words = X_train.iloc[i].split()\n",
        "        c = y_train.iloc[i]\n",
        "        for word in words:\n",
        "            class_word_counts[c][word] += 1\n",
        "\n",
        "    doc_freq = {}\n",
        "\n",
        "    for word in vocab:\n",
        "      doc_freq[word] = 0\n",
        "      for c in np.unique(y_train):\n",
        "        if class_word_counts[c][word] != 0:\n",
        "          doc_freq[word] += 1\n",
        "\n",
        "\n",
        "    # Compute the total count of words in each class\n",
        "    class_word_totals = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_totals[c] = sum(class_word_counts[c].values())\n",
        "\n",
        "    # Define a function to predict the class of a new text sample\n",
        "    def predict(text):\n",
        "        text = preprocess_sentence(text)\n",
        "        words = text.split()\n",
        "        probs = {}\n",
        "        for c in np.unique(y_train):\n",
        "            score = 0\n",
        "            for word in words:\n",
        "              if word in vocab:\n",
        "                if class_word_counts[c][word] != 0:\n",
        "                  score += (1 + np.log(class_word_counts[c][word]))\n",
        "                else:\n",
        "                  score += 0\n",
        "\n",
        "            probs[c] = score\n",
        "        return max(probs, key=probs.get)\n",
        "\n",
        "    # Evaluate the performance of the classifier on the testing data\n",
        "    correct = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for i in range(len(X_test)):\n",
        "        pred = predict(X_test.iloc[i])\n",
        "        if pred == 2:\n",
        "          # off = detect_offensive(X_test.iloc[i])\n",
        "          # if off == True:\n",
        "          #   if y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          #     correct += 1\n",
        "          # elif y_test.iloc[i] == 2:\n",
        "          #   correct += 1\n",
        "          if y_test.iloc[i] == 2:\n",
        "            tn += 1\n",
        "            correct += 1\n",
        "          else:\n",
        "            fn += 1\n",
        "        elif y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          tp += 1\n",
        "          correct += 1\n",
        "        else:\n",
        "          fp += 1\n",
        "    accuracy = correct / len(y_test)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Percision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "avg_recall = 0\n",
        "for i in range(10):\n",
        "    accuracy, precision, recall = basemodel(42 + 2 * i)\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "\n",
        "avg_accuracy /= 10\n",
        "avg_precision /= 10\n",
        "avg_recall /= 10\n",
        "\n",
        "print(\"average accuracy:\", avg_accuracy)\n",
        "print(\"average precision: \", avg_precision)\n",
        "print(\"average recall: \", avg_recall)\n",
        "f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "print(f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7kyBe5B2BbU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679243574861,
          "user_tz": -330,
          "elapsed": 39739,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "815766b4-7fef-48ca-b5d8-6a074b78e25f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8313817330210773\n",
            "Percision: 0.8302687411598303\n",
            "Recall: 1.0\n",
            "Accuracy: 0.8238875878220141\n",
            "Percision: 0.8227251296558227\n",
            "Recall: 1.0\n",
            "Accuracy: 0.839344262295082\n",
            "Percision: 0.8382075471698113\n",
            "Recall: 1.0\n",
            "Accuracy: 0.8374707259953161\n",
            "Percision: 0.8371873525247758\n",
            "Recall: 0.9988738738738738\n",
            "Accuracy: 0.8351288056206089\n",
            "Percision: 0.8340425531914893\n",
            "Recall: 0.9994334277620397\n",
            "Accuracy: 0.8384074941451991\n",
            "Percision: 0.8382838283828383\n",
            "Recall: 0.998876404494382\n",
            "Accuracy: 0.8304449648711943\n",
            "Percision: 0.829636621047664\n",
            "Recall: 0.9994314951677089\n",
            "Accuracy: 0.8449648711943794\n",
            "Percision: 0.8441190363722249\n",
            "Recall: 0.9994407158836689\n",
            "Accuracy: 0.8426229508196721\n",
            "Percision: 0.8416075650118203\n",
            "Recall: 0.9994385176866929\n",
            "Accuracy: 0.8374707259953161\n",
            "Percision: 0.83719829626124\n",
            "Recall: 0.9983069977426636\n",
            "average accuracy: 0.8361124121779862\n",
            "average precision:  0.8353276670777516\n",
            "average recall:  0.9993801432611029\n",
            "0.9100194362174151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the method Used:  score = Summation of (1 + log(tf)) * log(N/df)\n",
        "\n",
        "def basemodel2(rs):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df2['tweet'], df2['class'], test_size=0.2, random_state=rs)\n",
        "\n",
        "    # evaluting the vocabulary\n",
        "    vocab = set()\n",
        "    for sentence in X_train:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "\n",
        "    # Create a dictionary to store the count of each word in each class\n",
        "    # array of index = word for all labels\n",
        "    # count how many time a word occured in each labels\n",
        "\n",
        "    class_word_counts = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_counts[c] = {}\n",
        "        for word in vocab:\n",
        "            class_word_counts[c][word] = 0\n",
        "\n",
        "    # Count the number of occurrences of each word in each class\n",
        "    for i in range(len(X_train)):\n",
        "        words = X_train.iloc[i].split()\n",
        "        c = y_train.iloc[i]\n",
        "        for word in words:\n",
        "            class_word_counts[c][word] += 1\n",
        "\n",
        "    doc_freq = {}\n",
        "\n",
        "    for word in vocab:\n",
        "      doc_freq[word] = 0\n",
        "      for c in np.unique(y_train):\n",
        "        if class_word_counts[c][word] != 0:\n",
        "          doc_freq[word] += 1\n",
        "\n",
        "\n",
        "    # Compute the total count of words in each class\n",
        "    class_word_totals = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_totals[c] = sum(class_word_counts[c].values())\n",
        "\n",
        "    # Define a function to predict the class of a new text sample\n",
        "    def predict(text):\n",
        "        text = preprocess_sentence(text)\n",
        "        words = text.split()\n",
        "        probs = {}\n",
        "        for c in np.unique(y_train):\n",
        "            score = 0\n",
        "            for word in words:\n",
        "              if word in vocab:\n",
        "                if class_word_counts[c][word] != 0:\n",
        "                  score += (1 + np.log(class_word_counts[c][word])) * (1 + np.log(len(np.unique(y_train))/doc_freq[word]))\n",
        "                else:\n",
        "                  score += 0\n",
        "\n",
        "            probs[c] = score\n",
        "        return max(probs, key=probs.get)\n",
        "\n",
        "    # Evaluate the performance of the classifier on the testing data\n",
        "    correct = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for i in range(len(X_test)):\n",
        "        pred = predict(X_test.iloc[i])\n",
        "        if pred == 2:\n",
        "          # off = detect_offensive(X_test.iloc[i])\n",
        "          # if off == True:\n",
        "          #   if y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          #     correct += 1\n",
        "          # elif y_test.iloc[i] == 2:\n",
        "          #   correct += 1\n",
        "          if y_test.iloc[i] == 2:\n",
        "            tn += 1\n",
        "            correct += 1\n",
        "          else:\n",
        "            fn += 1\n",
        "        elif y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          tp += 1\n",
        "          correct += 1\n",
        "        else:\n",
        "          fp += 1\n",
        "    accuracy = correct / len(y_test)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Percision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "avg_recall = 0\n",
        "for i in range(10):\n",
        "    accuracy, precision, recall = basemodel2(42 + 2 * i)\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "\n",
        "avg_accuracy /= 10\n",
        "avg_precision /= 10\n",
        "avg_recall /= 10\n",
        "\n",
        "print(\"average accuracy:\", avg_accuracy)\n",
        "print(\"average precision: \", avg_precision)\n",
        "print(\"average recall: \", avg_recall)\n",
        "f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "print(f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5lp6f7V6DmJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679243495622,
          "user_tz": -330,
          "elapsed": 137826,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "8499419a-c563-4c07-c4be-9653adfa30e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8374707259953161\n",
            "Percision: 0.8353889943074004\n",
            "Recall: 1.0\n",
            "Accuracy: 0.8281030444964871\n",
            "Percision: 0.8262310606060606\n",
            "Recall: 1.0\n",
            "Accuracy: 0.8444964871194379\n",
            "Percision: 0.8429046037019459\n",
            "Recall: 0.9994372537985369\n",
            "Accuracy: 0.8398126463700234\n",
            "Percision: 0.8391674550614948\n",
            "Recall: 0.9988738738738738\n",
            "Accuracy: 0.839344262295082\n",
            "Percision: 0.8376068376068376\n",
            "Recall: 0.9994334277620397\n",
            "Accuracy: 0.8444964871194379\n",
            "Percision: 0.8434535104364327\n",
            "Recall: 0.998876404494382\n",
            "Accuracy: 0.8374707259953161\n",
            "Percision: 0.8358705994291151\n",
            "Recall: 0.9988629903354178\n",
            "Accuracy: 0.8463700234192038\n",
            "Percision: 0.8456439393939394\n",
            "Recall: 0.9988814317673378\n",
            "Accuracy: 0.8477751756440282\n",
            "Percision: 0.8460076045627376\n",
            "Recall: 0.9994385176866929\n",
            "Accuracy: 0.8426229508196721\n",
            "Percision: 0.8419047619047619\n",
            "Recall: 0.9977426636568849\n",
            "average accuracy: 0.8407962529274003\n",
            "average precision:  0.8394179367010726\n",
            "average recall:  0.9991546563375167\n",
            "0.9123472668348473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # the method Used: \n",
        "\n",
        "def tests(rs):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df2['tweet'], df2['class'], test_size=0.2, random_state=rs)\n",
        "\n",
        "    # evaluting the vocabulary\n",
        "    vocab = set()\n",
        "    for sentence in X_train:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "\n",
        "    # Create a dictionary to store the count of each word in each class\n",
        "    # array of index = word for all labels\n",
        "    # count how many time a word occured in each labels\n",
        "\n",
        "    class_word_counts = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_counts[c] = {}\n",
        "        for word in vocab:\n",
        "            class_word_counts[c][word] = 0\n",
        "\n",
        "    # Count the number of occurrences of each word in each class\n",
        "    for i in range(len(X_train)):\n",
        "        words = X_train.iloc[i].split()\n",
        "        c = y_train.iloc[i]\n",
        "        for word in words:\n",
        "            class_word_counts[c][word] += 1\n",
        "\n",
        "    # Prior probability of a class\n",
        "    class_priors = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_priors[c] = (len(y_train[y_train == c]) + 1) / (len(y_train) + len(np.unique(y_train)))\n",
        "\n",
        "\n",
        "    # Compute the total count of words in each class\n",
        "    class_word_totals = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_totals[c] = sum(class_word_counts[c].values())\n",
        "\n",
        "    # Define a function to predict the class of a new text sample\n",
        "    def predict(text):\n",
        "        text = preprocess_sentence(text)\n",
        "        words = text.split()\n",
        "        probs = {}\n",
        "        for c in np.unique(y_train):\n",
        "            log_prob = np.log(class_priors[c])\n",
        "            # log_prob = 1;\n",
        "            for word in words:\n",
        "              count = 1 # Laplace smoothing\n",
        "              if word in vocab:\n",
        "                  count += class_word_counts[c][word] \n",
        "              log_prob += np.log(count / (class_word_totals[c] + len(vocab)))\n",
        "            probs[c] = log_prob\n",
        "        return max(probs, key=probs.get)\n",
        "\n",
        "    # Evaluate the performance of the classifier on the testing data\n",
        "    correct = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for i in range(len(X_test)):\n",
        "        pred = predict(X_test.iloc[i])\n",
        "        if pred == 2:\n",
        "          # off = detect_offensive(X_test.iloc[i])\n",
        "          # if off == True:\n",
        "          #   if y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          #     correct += 1\n",
        "          # elif y_test.iloc[i] == 2:\n",
        "          #   correct += 1\n",
        "          if y_test.iloc[i] == 2:\n",
        "            tn += 1\n",
        "            correct += 1\n",
        "          else:\n",
        "            fn += 1\n",
        "        elif y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          tp += 1\n",
        "          correct += 1\n",
        "        else:\n",
        "          fp += 1\n",
        "    accuracy = correct / len(y_test)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Percision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "avg_recall = 0\n",
        "for i in range(10):\n",
        "    accuracy, precision, recall = tests(42 + 2 * i)\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "\n",
        "avg_accuracy /= 10\n",
        "avg_precision /= 10\n",
        "avg_recall /= 10\n",
        "\n",
        "print(\"average accuracy:\", avg_accuracy)\n",
        "print(\"average precision: \", avg_precision)\n",
        "print(\"average recall: \", avg_recall)\n",
        "f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "print(f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDXZKXWORHzj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679243061630,
          "user_tz": -330,
          "elapsed": 19388,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "0c1e2be5-00ca-445f-a9ad-f6b51a84fab1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9072599531615925\n",
            "Percision: 0.926815947569634\n",
            "Recall: 0.9636570130607609\n",
            "Accuracy: 0.9063231850117096\n",
            "Percision: 0.9205225911812738\n",
            "Recall: 0.969054441260745\n",
            "Accuracy: 0.9152224824355972\n",
            "Percision: 0.936542669584245\n",
            "Recall: 0.9634214969048959\n",
            "Accuracy: 0.9152224824355972\n",
            "Percision: 0.9360306178239475\n",
            "Recall: 0.963963963963964\n",
            "Accuracy: 0.9110070257611241\n",
            "Percision: 0.931980252331322\n",
            "Recall: 0.9626062322946176\n",
            "Accuracy: 0.9142857142857143\n",
            "Percision: 0.9304582210242588\n",
            "Recall: 0.9696629213483146\n",
            "Accuracy: 0.907728337236534\n",
            "Percision: 0.9295929592959296\n",
            "Recall: 0.9607731665719159\n",
            "Accuracy: 0.9217798594847775\n",
            "Percision: 0.9421713038734315\n",
            "Recall: 0.9658836689038032\n",
            "Accuracy: 0.9208430913348946\n",
            "Percision: 0.9366197183098591\n",
            "Recall: 0.9708029197080292\n",
            "Accuracy: 0.907728337236534\n",
            "Percision: 0.9282218597063622\n",
            "Recall: 0.9633182844243793\n",
            "average accuracy: 0.9127400468384076\n",
            "average precision:  0.9318956140700264\n",
            "average recall:  0.9653144108441424\n",
            "0.9483106813173678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "print(f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqdydUuqlfJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679242984481,
          "user_tz": -330,
          "elapsed": 9,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "957ce22d-c9a0-4f54-d592-dbf1f8a976a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.483106813173677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tests_another(rs):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df2['tweet'], df2['class'], test_size=0.2, random_state=rs)\n",
        "\n",
        "    # Define the vocabulary\n",
        "    vocab = set()\n",
        "    for sentence in X_train:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "\n",
        "    class_doc_counts = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_doc_counts[c] = {}\n",
        "        for word in vocab:\n",
        "            class_doc_counts[c][word] = 0\n",
        "\n",
        "    # Count the number of occurrences of each word in each class\n",
        "    for i in range(len(X_train)):\n",
        "        words = X_train.iloc[i].split()\n",
        "        c = y_train.iloc[i]\n",
        "        for word in np.unique(words):\n",
        "            class_doc_counts[c][word] += 1\n",
        "\n",
        "    # Prior probability of a class\n",
        "    class_priors = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_priors[c] = (len(y_train[y_train == c]) + 1) / (len(y_train) + len(np.unique(y_train)))\n",
        "\n",
        "    # Compute the total count of words in each class\n",
        "    class_docs_totals = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_docs_totals[c] = sum(class_doc_counts[c].values())\n",
        "\n",
        "    # Define a function to predict the class of a new text sample\n",
        "    def predict(text):\n",
        "        words = preprocess_sentence(text).split()\n",
        "        probs = {}\n",
        "        for c in np.unique(y_train):\n",
        "            log_prob = np.log(class_priors[c])\n",
        "            # log_prob = 1;\n",
        "            for word in words:\n",
        "              count = 1  # Laplace smoothing\n",
        "              if word in vocab:\n",
        "                  count += class_doc_counts[c][word]\n",
        "              log_prob += np.log(count / (class_docs_totals[c] + len(vocab)))\n",
        "            probs[c] = log_prob\n",
        "        return max(probs, key=probs.get)\n",
        "\n",
        "    # Evaluate the performance of the classifier on the testing data\n",
        "    correct = 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for i in range(len(X_test)):\n",
        "        pred = predict(X_test.iloc[i])\n",
        "        if pred == 2:\n",
        "          # off = detect_offensive(X_test.iloc[i])\n",
        "          # if off == True:\n",
        "          #   if y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          #     correct += 1\n",
        "          # elif y_test.iloc[i] == 2:\n",
        "          #   correct += 1\n",
        "          if y_test.iloc[i] == 2:\n",
        "            tn += 1\n",
        "            correct += 1\n",
        "          else:\n",
        "            fn += 1\n",
        "        elif y_test.iloc[i] == 0 or y_test.iloc[i] == 1:\n",
        "          tp += 1\n",
        "          correct += 1\n",
        "        else:\n",
        "          fp += 1\n",
        "    accuracy = correct / len(y_test)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Percision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "avg_recall = 0\n",
        "for i in range(10):\n",
        "    accuracy, precision, recall = tests_another(42 + 2 * i)\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "\n",
        "avg_accuracy /= 10\n",
        "avg_precision /= 10\n",
        "avg_recall /= 10\n",
        "\n",
        "print(\"average accuracy:\", avg_accuracy)\n",
        "print(\"average precision: \", avg_precision)\n",
        "print(\"average recall: \", avg_recall)\n",
        "f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "print(f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hlb2ud3eLXa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1679243262860,
          "user_tz": -330,
          "elapsed": 22720,
          "user": {
            "displayName": "Atishay Jain",
            "userId": "12129055538829762545"
          }
        },
        "outputId": "3bbcbb72-ce40-4f34-ceb6-22c54abc494d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9039812646370023\n",
            "Percision: 0.9147121535181236\n",
            "Recall: 0.9744463373083475\n",
            "Accuracy: 0.8899297423887588\n",
            "Percision: 0.8986272439281943\n",
            "Recall: 0.9753581661891118\n",
            "Accuracy: 0.9072599531615925\n",
            "Percision: 0.9197235513024987\n",
            "Recall: 0.9735509285312324\n",
            "Accuracy: 0.9096018735362997\n",
            "Percision: 0.924396782841823\n",
            "Recall: 0.9707207207207207\n",
            "Accuracy: 0.9053864168618267\n",
            "Percision: 0.9137109581789307\n",
            "Recall: 0.9779036827195468\n",
            "Accuracy: 0.9081967213114754\n",
            "Percision: 0.916403785488959\n",
            "Recall: 0.9792134831460674\n",
            "Accuracy: 0.9021077283372365\n",
            "Percision: 0.9148822269807281\n",
            "Recall: 0.9715747583854463\n",
            "Accuracy: 0.9199063231850118\n",
            "Percision: 0.9298245614035088\n",
            "Recall: 0.9781879194630873\n",
            "Accuracy: 0.9175644028103045\n",
            "Percision: 0.9239302694136292\n",
            "Recall: 0.9820325659741718\n",
            "Accuracy: 0.907728337236534\n",
            "Percision: 0.9168872419269455\n",
            "Recall: 0.9774266365688488\n",
            "average accuracy: 0.9071662763466042\n",
            "average precision:  0.9173098774983341\n",
            "average recall:  0.9760415199006582\n",
            "0.9457647727551592\n"
          ]
        }
      ]
    }
  ]
}